{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfEBJPTqf0knQbmlF2rzUW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VnmXx6PRoPY","executionInfo":{"status":"ok","timestamp":1749839059101,"user_tz":-540,"elapsed":1524,"user":{"displayName":"Eunyoung Ko","userId":"11209452883220882329"}},"outputId":"1f4c2bbc-4af1-4d7c-a692-f6eba1e0774d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 1. CNN 구성"],"metadata":{"id":"mwae-wjmgw_V"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from PIL import Image, UnidentifiedImageError\n","from collections import defaultdict\n","import random\n","\n","class ImprovedCNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(ImprovedCNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","\n","            nn.Dropout(0.3)\n","        )\n","\n","        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.pool(x)\n","        x = self.classifier(x)\n","        return x\n"],"metadata":{"id":"QwI9r_bbfLj1","executionInfo":{"status":"ok","timestamp":1749839142476,"user_tz":-540,"elapsed":13234,"user":{"displayName":"Eunyoung Ko","userId":"11209452883220882329"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# 2. 레이블 인코더"],"metadata":{"id":"j8i4WUthgzzN"}},{"cell_type":"code","source":["import json\n","\n","class_names = [\n","    \"코리안 숏헤어\",      # 0\n","    \"러시안블루\",        # 1\n","    \"페르시안\",          # 2\n","    \"스코티쉬 스트레이드\", # 3\n","    \"스코티쉬 폴드\",      # 4\n","    \"시암\",              # 5\n","    \"터키시 앙고라\",      # 6\n","    \"먼치킨\",            # 7\n","    \"브리티쉬 숏헤어\",    # 8\n","    \"래그돌\"             # 9\n","]\n","\n","inverse_label_encoder = {idx: name for idx, name in enumerate(class_names)}\n","\n","\n","with open(\"/content/gdrive/MyDrive/03. KOREA UNI/2. Deep Learning/프로젝트/inverse_label_encoder.json\", \"w\", encoding=\"utf-8\") as f:\n","  json.dump(inverse_label_encoder, f, ensure_ascii=False, indent=4)\n","\n","with open(\"/content/gdrive/MyDrive/03. KOREA UNI/2. Deep Learning/프로젝트/inverse_label_encoder.json\", \"r\", encoding=\"utf-8\") as f:\n","  inverse_label_encoder = json.load(f)\n"],"metadata":{"id":"fBTk7r8vKVVJ","executionInfo":{"status":"ok","timestamp":1749839223058,"user_tz":-540,"elapsed":30,"user":{"displayName":"Eunyoung Ko","userId":"11209452883220882329"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# 3. 추론"],"metadata":{"id":"HcMrjTDig31L"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"hhxOqHqdueOo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749839186937,"user_tz":-540,"elapsed":698,"user":{"displayName":"Eunyoung Ko","userId":"11209452883220882329"}},"outputId":"3dd67503-96fe-4a1a-f2f9-80f19dc9dd0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["KakaoTalk_Photo_2025-06-07-17-46-36 004.jpeg → 예측 품종: 먼치킨\n","KakaoTalk_Photo_2025-06-07-17-46-36 003.jpeg → 예측 품종: 페르시안\n","KakaoTalk_Photo_2025-06-07-17-46-35 002.jpeg → 예측 품종: 코리안 숏헤어\n","KakaoTalk_Photo_2025-06-07-17-46-35 001.jpeg → 예측 품종: 코리안 숏헤어\n"]}],"source":["from torchvision import transforms\n","def predict(image_path, model, label_encoder, transform, device):\n","    image = Image.open(image_path).convert('RGB')\n","    img_t = transform(image).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(img_t)\n","        _, pred = torch.max(outputs, 1)\n","        breed = label_encoder.get(pred.cpu().numpy()[0].item())\n","    return breed\n","\n","# 이미지 변환 정의\n","transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406],\n","                         std=[0.229,0.224,0.225]),\n","])\n","\n","\n","test_data_list =[\n","'KakaoTalk_Photo_2025-06-07-17-46-36 004.jpeg'\n",",'KakaoTalk_Photo_2025-06-07-17-46-36 003.jpeg'\n",",'KakaoTalk_Photo_2025-06-07-17-46-35 002.jpeg'\n",",'KakaoTalk_Photo_2025-06-07-17-46-35 001.jpeg']\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = ImprovedCNN(num_classes=10).to(device)\n","model.load_state_dict(torch.load( \"/content/gdrive/MyDrive/03. KOREA UNI/2. Deep Learning/프로젝트/MODEL/cnn_model_top10_v3.pth\", map_location=device))\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    for img in test_data_list:\n","        test_image_path = '/content/gdrive/MyDrive/03. KOREA UNI/2. Deep Learning/프로젝트/TEST_DATA/' + img\n","        predicted_breed = predict(test_image_path, model, inverse_label_encoder, transform, device)\n","        print(f\"{img} → 예측 품종: {predicted_breed}\")\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"BuWcRL-fLMrK"},"execution_count":null,"outputs":[]}]}